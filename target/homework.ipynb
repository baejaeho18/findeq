import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
from nltk.probability import FreqDist

# Read the CSV file
df = pd.read_csv('amazon_train_df.csv')

# Tokenize and process each review
for review in df['4']:
    # Tokenize the review into individual words
    tokens = word_tokenize(review)
    
    # Calculate the frequency distribution of the words
    fdist = FreqDist(tokens)
    
    # Get the five most frequent words
    top_words = fdist.most_common(5)
    
    # Print the top words for the current review
    print(f"Review: {review}")
    print("Top 5 words:")
    for word, count in top_words:
        print(f"{word},", end=" ")
    print("\n---")

